{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "## 🔧 Setup (required once)\n",
    "\n",
    "| Variable / field | Purpose | How to provide |\n",
    "|------------------|---------|----------------|\n",
    "| **USER_AGENT** | Identifies you in HTTP headers when scraping EDGAR. | Export `USER_AGENT=\"Ada <ada@example.com>\"` before launching Jupyter **or** enter one when the setup cell prompts you. |\n",
    "| **OPENAI_API_KEY** | Needed for any cell that calls OpenAI. | Export `OPENAI_API_KEY=\"sk-...\"` **or** paste it when prompted in the setup cell. |\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ╔════════════════════════════════════════════════════╗\n",
    "# ║  Setup – supply per-user secrets & identifiers     ║\n",
    "# ╚════════════════════════════════════════════════════╝\n",
    "#\n",
    "# Priority for each variable:\n",
    "#   1. Environment variable (best for CI / .env files)\n",
    "#   2. Interactive prompt (OPENAI key) or fallback literal (USER_AGENT)\n",
    "#   3. Users can always overwrite later in the notebook.\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "# ---------- USER_AGENT --------------------------------------------\n",
    "USER_AGENT = os.getenv(\"USER_AGENT\")\n",
    "if not USER_AGENT:                      # fall back to a polite prompt\n",
    "    USER_AGENT = input(\n",
    "        \"📝  Enter a USER_AGENT for EDGAR \"\n",
    "        '(e.g. \"Ada Lovelace <ada@example.com>\"): '\n",
    "    ).strip()\n",
    "    if not USER_AGENT:\n",
    "        sys.exit(\"❌  USER_AGENT is required for EDGAR scraping.\")\n",
    "\n",
    "print(f\"✅ USER_AGENT set to: {USER_AGENT}\")\n",
    "\n",
    "# ---------- OPENAI_API_KEY ----------------------------------------\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:                  # secret → use getpass\n",
    "    try:\n",
    "        OPENAI_API_KEY = getpass(\"🔑  Paste your OpenAI API key: \")\n",
    "    except EOFError:\n",
    "        sys.exit(\"❌ OPENAI_API_KEY is required for OpenAI calls.\")\n",
    "\n",
    "# Instantiate a single OpenAI client for reuse\n",
    "from openai import OpenAI\n",
    "client_openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "print(\"✅ OpenAI client initialised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ╔════════════════════════════════════════════════════╗\n",
    "# ║ 1.  Imports                                        ║\n",
    "# ╚════════════════════════════════════════════════════╝\n",
    "# ——— standard library ————————————————————————————\n",
    "import argparse\n",
    "import datetime as dt\n",
    "import importlib\n",
    "import inspect\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# ——— third-party ————————————————————————————————\n",
    "import boto3\n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Allow local helper modules (optional)\n",
    "sys.path.insert(0, \"/tmp\")\n",
    "\n",
    "# ╔════════════════════════════════════════════════════╗\n",
    "# ║ 2.  Global configuration                           ║\n",
    "# ╚════════════════════════════════════════════════════╝\n",
    "RUN_ID   = uuid.uuid4().hex[:8]\n",
    "\n",
    "# Validator tolerance  (±5 %)\n",
    "LOWER_TOL_FACTOR = 0.95\n",
    "UPPER_TOL_FACTOR = 1.05\n",
    "\n",
    "# OpenAI\n",
    "completions_model_choice = \"gpt-4o\"\n",
    "OPENAI_API_KEY           = os.getenv(\"OPENAI_API_KEY\")  # or Secrets Manager helper\n",
    "\n",
    "max_tokens_api = 3000\n",
    "retry_max_api = 50\n",
    "temperature_api = 0\n",
    "n_api = 1\n",
    "sleep_time_lower_bound = 1.00\n",
    "sleep_time_upper_bound = 1.10\n",
    "sleep_time = random.uniform(sleep_time_lower_bound, sleep_time_upper_bound)\n",
    "\n",
    "# Cost model\n",
    "MIN_WAGE   = 0.50                      # $ / reviewer-minute\n",
    "MODEL_COST = {\"accept\": 0.001,\n",
    "              \"reject\": 0.001,\n",
    "              \"defer\" : 0.001,\n",
    "              \"unresolved\": 0.001}\n",
    "\n",
    "# ── choose where to drop artefacts ────────────────────────────────\n",
    "OUT_DIR = Path.cwd() / \"outputs\"          # always visible in UI\n",
    "OUT_DIR.mkdir(exist_ok=True)              # parents=True not needed here\n",
    "\n",
    "GT_PATH   = OUT_DIR / \"ground_truth.csv\"\n",
    "PASS1_OUT = OUT_DIR / f\"ledger_pass1_{RUN_ID}.jsonl\"\n",
    "PASS2_OUT = OUT_DIR / f\"ledger_pass2_{RUN_ID}.jsonl\"\n",
    "\n",
    "print(\"Working directory :\", Path.cwd())\n",
    "print(\"Artefacts will go :\", OUT_DIR)\n",
    "\n",
    "# Randomised back-off for OpenAI retries\n",
    "sleep_time = random.uniform(1.00, 1.10)\n",
    "\n",
    "# ╔════════════════════════════════════════════════════╗\n",
    "# ║ 3.  AWS / OpenAI clients                           ║\n",
    "# ╚════════════════════════════════════════════════════╝\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# ╔════════════════════════════════════════════════════╗\n",
    "# ║ 4.  Static lookup tables & regex helpers           ║\n",
    "# ╚════════════════════════════════════════════════════╝\n",
    "USER_AGENT = \"Your Name <your email>\"\n",
    "CACHE_DIR  = pathlib.Path(\".sec_cache\"); CACHE_DIR.mkdir(exist_ok=True)\n",
    "INPUT_FILE_GROUND_TRUTH = OUT_DIR / \"benchmark_queries_100_FY2021_FY2023.csv\"\n",
    "OUT_FILE_GROUND_TRUTH = OUT_DIR / \"ground_truth.csv\"\n",
    "\n",
    "GAAP_MAP = {\n",
    "    \"Revenue\": [\"Revenues\",\n",
    "                \"RevenueFromContractWithCustomerExcludingAssessedTax\"],\n",
    "    \"Net Income\": [\"NetIncomeLoss\"],\n",
    "    \"EBITDA\": [\"EarningsBeforeInterestTaxesDepreciationAmortization\"],\n",
    "    \"Operating Income\": [\"OperatingIncomeLoss\"],\n",
    "    \"Total Assets\": [\"Assets\"],\n",
    "    \"EPS (diluted)\": [\"EarningsPerShareDiluted\"],\n",
    "    \"Total Equity\": [\"StockholdersEquity\"],\n",
    "    \"Shares Outstanding (diluted)\": [\"WeightedAverageNumberOfDilutedSharesOutstanding\"],\n",
    "    \"Cash From Operations\": [\"NetCashProvidedByUsedInOperatingActivities\"]\n",
    "}\n",
    "CIK_LOOKUP = {\n",
    "    \"AAPL\": \"0000320193\",\n",
    "    \"MSFT\": \"0000789019\",\n",
    "    \"AMZN\": \"0001018724\",\n",
    "    \"NVDA\": \"0001045810\",\n",
    "    \"JPM\":  \"0000019617\",\n",
    "    \"META\": \"0001326801\",\n",
    "    \"GOOGL\": \"0001652044\",\n",
    "    \"BRK.B\": \"0001067983\",\n",
    "    \"KO\":   \"0000021344\",\n",
    "    \"BAC\":  \"0000070858\",\n",
    "}\n",
    "\n",
    "IDK_PATTERNS = [\n",
    "    r\"\\bdo(?:\\s+not|n't)\\s+have\\s+(?:access|the information)\",\n",
    "    r\"\\bno\\s+.*real[- ]time\\s+data\",\n",
    "    r\"\\bi\\s+don't\\s+have\\s+the\\s+specific\",\n",
    "    r\"\\bnot\\s+available\\b\",\n",
    "]\n",
    "\n",
    "UNIT_MULT = {\n",
    "    \"trillion\": 1e12, \"tn\": 1e12, \"t\": 1e12,\n",
    "    \"billion\": 1e9,   \"bn\": 1e9,  \"b\": 1e9,\n",
    "    \"million\": 1e6,   \"mn\": 1e6,  \"m\": 1e6,\n",
    "    \"thousand\": 1e3,  \"k\": 1e3,\n",
    "    \"\": 1.0,\n",
    "}\n",
    "\n",
    "num_re = re.compile(\n",
    "    r\"\"\"\n",
    "    (?P<sign>[-+]?)\\s*\n",
    "    (?P<int>(?:\\d{1,3}(?:[,\\s]\\d{3})+|\\d+))   # <‑‑ re‑ordered\n",
    "    (?:\\.(?P<frac>\\d+))?\n",
    "    \\s*\n",
    "    (?P<unit>trillion|bn|billion|mn|million|k|thousand|t|m|b)?\n",
    "    \\b\n",
    "    \"\"\",\n",
    "    re.IGNORECASE | re.VERBOSE,\n",
    ")\n",
    "\n",
    "# ╔════════════════════════════════════════════════════╗\n",
    "# ║ 5.  Pre-allocate ledgers (empty lists)             ║\n",
    "# ╚════════════════════════════════════════════════════╝\n",
    "ledger_pass1 = []\n",
    "ledger_pass2 = []\n",
    "\n",
    "COLOR_PASS1 = \"tab:blue\"\n",
    "COLOR_PASS2 = \"tab:orange\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_openai(messages, max_tokens=max_tokens_api, stop=None, retry_max=retry_max_api, model=completions_model_choice):\n",
    "    \"\"\"\n",
    "    Wrapper around OpenAI Chat Completions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    messages : str | list[dict]\n",
    "        Either a single prompt string or a chat-style list with 'role'/'content'.\n",
    "    max_tokens : int\n",
    "        Hard upper-bound on tokens to sample.\n",
    "    stop : list[str] | None\n",
    "        Forwarded to OpenAI to stop generation on any of these strings.\n",
    "    retry_max : int\n",
    "        Retry count on *any* exception.\n",
    "    model : str\n",
    "        Model name to pass through.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Assistant's raw text reply (stripped of outer quotes).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * Converts a bare string into `[{\"role\": \"user\", \"content\": ...}]`.\n",
    "    * Sleeps `sleep_time` seconds between retries (simple linear backoff).\n",
    "    * Raises `Exception` if still failing after `retry_max` attempts.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(messages, str):  # If the input is just a single string, wrap it in the appropriate structure.\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "\n",
    "    response = None\n",
    "    retries = 0\n",
    "    while retries < retry_max:\n",
    "        try:\n",
    "            response = client_openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                n=1,\n",
    "                stop=stop,\n",
    "                temperature=0\n",
    "            )\n",
    "            # Assuming the response is a pydantic model, we can access attributes directly\n",
    "            content = response.choices[0].message.content.strip('\"')\n",
    "            return content\n",
    "        except Exception as e:  # Catching any exception\n",
    "            print(f\"Error: {e}\")\n",
    "            retries += 1\n",
    "            if retries >= retry_max:\n",
    "                raise Exception(\"API call failed after maximum retries.\")\n",
    "            time.sleep(sleep_time)  # Wait for random seconds before retrying\n",
    "\n",
    "    raise Exception(\"Failed to receive a valid response from OpenAI API.\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# SEC DOWNLOAD + PARSING HELPERS\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def sec_companyfacts(cik: str) -> dict:\n",
    "    \"\"\"\n",
    "    Download (or read cached) SEC CompanyFacts JSON for a given CIK.\n",
    "\n",
    "    * Pads CIK to 10 digits.\n",
    "    * Caches raw JSON under .sec_cache/CIK##########.json.\n",
    "    * Sleeps `sleep_time` after a network hit to stay polite.\n",
    "    \"\"\"\n",
    "    cik10 = cik.zfill(10)\n",
    "    cache = CACHE_DIR / f\"{cik10}.json\"\n",
    "    if cache.exists():\n",
    "        return json.loads(cache.read_text())\n",
    "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik10}.json\"\n",
    "    r = requests.get(url, headers={\"User-Agent\": USER_AGENT}, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    cache.write_text(r.text)\n",
    "    time.sleep(sleep_time)\n",
    "    return r.json()\n",
    "\n",
    "def best_10k_item(items: list[dict], fy: int):\n",
    "    \"\"\"\n",
    "    Pick the most authoritative FY record from a list of XBRL facts.\n",
    "\n",
    "    Priority order\n",
    "    --------------\n",
    "    1. Exact FY + form == '10-K'\n",
    "    2. Exact FY + form == '10-K/A'\n",
    "    3. If multiple matches, choose the one with the latest 'end' date.\n",
    "    \"\"\"\n",
    "    same_fy = [it for it in items if it.get(\"fy\") == fy]\n",
    "    # split plain vs amended\n",
    "    plain   = [it for it in same_fy if it.get(\"form\") == \"10-K\"]\n",
    "    amended = [it for it in same_fy if it.get(\"form\") == \"10-K/A\"]\n",
    "\n",
    "    def latest(lst):                 # helper returns latest by `end`\n",
    "        return max(lst, key=lambda d: d.get(\"end\", \"0000-00-00\"))\n",
    "\n",
    "    if plain:\n",
    "        return latest(plain)\n",
    "    if amended:\n",
    "        return latest(amended)\n",
    "    return None\n",
    "\n",
    "\n",
    "def fy_value(facts: dict, tags: list[str], fy: int):\n",
    "    \"\"\"\n",
    "    Return (value, unit) for a metric in a specific fiscal year.\n",
    "\n",
    "    Strategy\n",
    "    --------\n",
    "    * Strict FY match using `best_10k_item`.\n",
    "    * If nothing found, fall back to fp=='FY' that ends within calendar year.\n",
    "    * Prefers '10-K' over '10-K/A'; picks latest end-date among duplicates.\n",
    "    \"\"\"\n",
    "    for tag in tags:\n",
    "        unit_dict = facts.get(\"facts\", {}).get(\"us-gaap\", {}).get(tag, {}).get(\"units\", {})\n",
    "        for unit, items in unit_dict.items():\n",
    "            best = best_10k_item(items, fy)\n",
    "            if best:\n",
    "                return best[\"val\"], unit\n",
    "\n",
    "        # ---------- fallback: match by date span -----------------\n",
    "        yr_start, yr_end = dt.date(fy, 1, 1), dt.date(fy, 12, 31)\n",
    "        for unit, items in unit_dict.items():\n",
    "            fy_items = [\n",
    "                it for it in items\n",
    "                if it.get(\"fp\") == \"FY\"\n",
    "                and \"end\" in it\n",
    "                and yr_start <= dt.date.fromisoformat(it[\"end\"]) <= yr_end\n",
    "            ]\n",
    "            if fy_items:\n",
    "                best = max(fy_items, key=lambda d: d[\"end\"])\n",
    "                return best[\"val\"], unit\n",
    "    return None\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CSV ENRICHMENT\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def enrich(csv_path: Path = INPUT_FILE_GROUND_TRUTH) -> None:\n",
    "    \"\"\"\n",
    "    Populate 'answer' and 'unit' columns in the benchmark CSV, in-place.\n",
    "\n",
    "    * Ensures columns have correct dtypes (float64, string).\n",
    "    * Pulls CompanyFacts for each unique ticker (cached).\n",
    "    * Writes the updated CSV back to `csv_path`.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # ensure dtype compatibility before we start writing floats / strings\n",
    "    df[\"answer\"] = df.get(\"answer\", pd.Series(index=df.index, dtype=\"float64\")).astype(\"float64\")\n",
    "    df[\"unit\"]   = df.get(\"unit\",   pd.Series(index=df.index, dtype=\"string\")).astype(\"string\")\n",
    "\n",
    "    # cache SEC JSON once per ticker\n",
    "    facts_cache = {tkr: sec_companyfacts(CIK_LOOKUP[tkr])\n",
    "                   for tkr in df[\"ticker\"].unique()}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        tags = GAAP_MAP.get(row[\"metric\"])\n",
    "        if not tags:\n",
    "            continue\n",
    "        res = fy_value(facts_cache[row[\"ticker\"]], tags, int(row[\"period\"]))\n",
    "        if res:\n",
    "            val, unit = res\n",
    "            df.at[idx, \"answer\"] = val\n",
    "            df.at[idx, \"unit\"]   = unit\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"✅ wrote {csv_path.resolve()}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# NUMERIC EXTRACTION + LLM HELPERS\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def looks_like_idk(text: str) -> bool:\n",
    "    \"\"\"Heuristic: does the draft answer contain an 'I don't know' disclaimer?\"\"\"\n",
    "    return any(re.search(pat, text, re.I) for pat in IDK_PATTERNS)\n",
    "\n",
    "def parse_numeric(text: str) -> float | None:\n",
    "    \"\"\"\n",
    "    Extract first numeric token + magnitude unit, return value in raw USD.\n",
    "\n",
    "    * Recognises trillion / billion / million / thousand suffixes.\n",
    "    * Returns None if pattern or unit missing.\n",
    "    \"\"\"\n",
    "    match = num_re.search(text.replace(\"$\", \"\"))\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    whole = match.group(\"int\").replace(\",\", \"\").replace(\" \", \"\")\n",
    "    frac  = match.group(\"frac\") or \"\"\n",
    "    sign  = -1 if match.group(\"sign\") == \"-\" else 1\n",
    "    val   = float(f\"{whole}.{frac}\") if frac else float(whole)\n",
    "    unit  = (match.group(\"unit\") or \"\").lower()\n",
    "\n",
    "    mult  = UNIT_MULT.get(unit, None)\n",
    "    if mult is None:\n",
    "        return None                      # unknown unit string\n",
    "    return sign * val * mult\n",
    "\n",
    "# ---------- helpers -----------------------------------\n",
    "def generator_llm(q: str) -> str:\n",
    "    \"\"\"Call `ask_openai` with zero-temperature to produce a draft answer.\"\"\"\n",
    "    return ask_openai(\n",
    "        messages=[{\"role\": \"user\", \"content\": q}]\n",
    "    )\n",
    "\n",
    "def referee_llm_det(q: str, draft: str, lo: float, hi: float) -> bool:\n",
    "    \"\"\"\n",
    "    Deterministic validator for numeric queries.\n",
    "\n",
    "    Workflow\n",
    "    --------\n",
    "    1. `looks_like_idk` → 'defer'\n",
    "    2. `parse_numeric` → 'defer' on failure\n",
    "    3. Accept if `lo <= value <= hi`, else 'reject'\n",
    "    \"\"\"\n",
    "    if looks_like_idk(draft):\n",
    "        return \"defer\"             # new state\n",
    "    val = parse_numeric(draft)\n",
    "    #print(f\"[REFEREE] Q='{q[:60]}…'  draft='{draft[:60]}…'  parsed_val={val}\")\n",
    "    if val is None:\n",
    "        return \"defer\"             # couldn’t extract number\n",
    "    return \"accept\" if lo <= val <= hi else \"reject\"\n",
    "\n",
    "def judge_external(row, reason):\n",
    "    \"\"\"\n",
    "    Simulated human fallback (External Judge).\n",
    "\n",
    "    * Always returns authoritative `row.answer`.\n",
    "    * Adds 60 s latency & 1.0 human_min.\n",
    "    * `reason` informs provenance tag.\n",
    "    \"\"\"\n",
    "    answer  = row.answer      # authoritative value\n",
    "    latency = 60              # seconds of expert lookup (simulated)\n",
    "    provenance = f\"fallback:{reason}\"\n",
    "    return answer, 1.0, provenance     # value, human_min, tag\n",
    "\n",
    "def write_memory(query_hash, answer):\n",
    "    \"\"\"\n",
    "    Persist an accepted answer to precedent store (stub in toy demo).\n",
    "    \"\"\"\n",
    "    # stub for future precedent store\n",
    "    pass\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# KPI + PLOTTING\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def compute_kpi(ledger_path: str, storage_opts=None) -> dict:\n",
    "    \"\"\"\n",
    "    Load a JSONL ledger and compute acceptance / cost metrics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict  keys include:\n",
    "        accept_rate, reject_rate, defer_rate, coverage_rate,\n",
    "        avg_latency_s, total_human_min, total_cost_$\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_json(ledger_path, lines=True, storage_options=storage_opts or {})\n",
    "\n",
    "    # pick the latest state column: state, state_p2, state_p3 ...\n",
    "    state_cols = sorted([c for c in df.columns if re.match(r\"state(_p\\d+)?$\", c)])\n",
    "    state_col  = state_cols[-1]\n",
    "\n",
    "    N  = len(df)\n",
    "    counts = df[state_col].value_counts()\n",
    "    accept = (df[state_col] == \"accept\").sum()\n",
    "    reject = (df[state_col] == \"reject\").sum()\n",
    "    defer  = (df[state_col] == \"defer\").sum()\n",
    "    unres  = (df[state_col] == \"unresolved\").sum() if \"unresolved\" in df[state_col].values else 0\n",
    "\n",
    "    # monetise\n",
    "    df[\"dollars\"] = (\n",
    "          df[state_col].map(MODEL_COST).fillna(0)\n",
    "        + df[\"human_min\"] * MIN_WAGE\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"ledger\"          : ledger_path,\n",
    "        \"state_column\"    : state_col,\n",
    "        \"total_queries\"   : N,\n",
    "        \"accept_rate\"     : accept / N,\n",
    "        \"reject_rate\"     : reject / N,\n",
    "        \"defer_rate\"      : defer  / N,\n",
    "        \"unresolved_rate\" : unres  / N,\n",
    "        \"coverage_rate\"   : (accept + reject) / N,\n",
    "        \"avg_latency_s\"   : df.latency_s.mean(),\n",
    "        \"total_human_min\" : df.human_min.sum(),\n",
    "        \"total_cost_$\"    : df.dollars.sum(),\n",
    "    }\n",
    "\n",
    "def plot_comparison(kpi1: dict, kpi2: dict, out_dir: Path | None = None):\n",
    "    \"\"\"\n",
    "    Side-by-side bar charts:\n",
    "\n",
    "    * Chart 1 — accept / reject / defer share, coloured consistently.\n",
    "    * Chart 2 — total \\$ cost per pass.\n",
    "\n",
    "    Saves PNGs to `out_dir` when provided (README-ready).\n",
    "    \"\"\"\n",
    "    label1, label2 = \"Pass 1\", \"Pass 2\"      # or kpi1[\"ledger\"].stem, …\n",
    "\n",
    "    # ── chart 1  (classification mix) ──────────────────────────────\n",
    "    cats  = [\"accept_rate\", \"reject_rate\", \"defer_rate\"]\n",
    "    y1    = [kpi1[c] for c in cats]\n",
    "    y2    = [kpi2[c] for c in cats]\n",
    "    x     = range(len(cats))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3), constrained_layout=True)\n",
    "    ax.bar([xi - width/2 for xi in x], y1, width,\n",
    "           label=label1, color=COLOR_PASS1)\n",
    "    ax.bar([xi + width/2 for xi in x], y2, width,\n",
    "           label=label2, color=COLOR_PASS2)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([c.replace(\"_rate\", \"\") for c in cats])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(\"fraction\")\n",
    "    ax.set_title(\"Classifications per pass\")\n",
    "    ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.18),\n",
    "              ncol=2, frameon=False)\n",
    "\n",
    "    if out_dir:\n",
    "        fig.savefig(out_dir / \"kpi_bar.png\", dpi=120, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # ── chart 2  (total $ cost) ───────────────────────────────────\n",
    "    fig2, ax2 = plt.subplots(figsize=(4, 3), constrained_layout=True)\n",
    "    ax2.bar(0, kpi1[\"total_cost_$\"], color=COLOR_PASS1, label=label1)\n",
    "    ax2.bar(1, kpi2[\"total_cost_$\"], color=COLOR_PASS2, label=label2)\n",
    "\n",
    "    ax2.set_xticks([0, 1])\n",
    "    ax2.set_xticklabels([label1, label2])\n",
    "    ax2.set_ylabel(\"$ total cost\")\n",
    "    ax2.set_title(\"End-to-end cost\")\n",
    "    ax2.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15),\n",
    "               ncol=2, frameon=False)\n",
    "\n",
    "    if out_dir:\n",
    "        fig2.savefig(out_dir / \"cost_bar.png\", dpi=120, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# ─── Change in cost / accepted query ───────────────────────────────\n",
    "def cost_per_accept(kpi: dict) -> float | None:\n",
    "    \"\"\"Return $/accept or None if there were zero accepts.\"\"\"\n",
    "    n_acc = int(round(kpi[\"accept_rate\"] * kpi[\"total_queries\"]))\n",
    "    return kpi[\"total_cost_$\"] / n_acc if n_acc else None\n",
    "\n",
    "def pretty_print_kpi(k: dict) -> None:\n",
    "    \"\"\"Readable console dump of key KPI fields + monetised cost.\"\"\"\n",
    "    print(\"\\n== KPI Summary ==\")\n",
    "    for key in [\n",
    "        \"total_queries\", \"accept_rate\", \"reject_rate\", \"defer_rate\",\n",
    "        \"unresolved_rate\", \"coverage_rate\", \"avg_latency_s\",\n",
    "        \"total_human_min\",\n",
    "    ]:\n",
    "        val = k[key]\n",
    "        print(f\"{key:20}: {val:.3f}\" if isinstance(val, float) else\n",
    "              f\"{key:20}: {val}\")\n",
    "    print(f\"\\nEstimated total $ cost: ${k['total_cost_$']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "fill_answers_from_sec.py\n",
    "Populate the 'answer' column of the 100‑query benchmark CSV\n",
    "using SEC Company Facts data (10‑K).  Tolerates Jupyter's -f flag.\n",
    "\"\"\"\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"--csv\", default=str(OUT_FILE_GROUND_TRUTH),\n",
    "                help=\"Input benchmark CSV (local path).\")\n",
    "args, _rest = ap.parse_known_args()\n",
    "enrich(Path(args.csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# ║ PASS-1  ·  Deterministic “validator” loop                            ║\n",
    "# ╠──────────────────────────────────────────────────────────────────────╣\n",
    "# ║ • For each benchmark query we:                                      ║\n",
    "# ║     1. Ask the generator LLM for a draft numeric answer.            ║\n",
    "# ║     2. Parse that draft deterministically (`referee_llm_det`).      ║\n",
    "# ║     3. Accept if it falls within ±5 % of the ground-truth value     ║\n",
    "# ║        (bounds = answer·LOWER_TOL_FACTOR .. answer·UPPER_TOL_FACTOR)║\n",
    "# ║        — the validator never sees the exact ground-truth.           ║\n",
    "# ║     4. Reject ➜ call simulated External Judge (adds human cost).    ║\n",
    "# ║     5. Defer ➜ leave unanswered this pass (no judge, no memory).    ║\n",
    "# ║ • Each iteration is timed and a JSON-serialisable record is pushed  ║\n",
    "# ║   to `ledger_pass1`.                                                ║\n",
    "# ║ • At the end we write the ledger to  ./outputs/ledger_pass1_<id>.   ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "# ---------- load ground truth -------------------------\n",
    "df_gt = pd.read_csv(GT_PATH)\n",
    "\n",
    "for _, row in df_gt.iterrows():\n",
    "    q, lo, hi = row.query, row.answer * LOWER_TOL_FACTOR, row.answer * UPPER_TOL_FACTOR\n",
    "    t0 = time.time()\n",
    "    draft = generator_llm(q)\n",
    "    state = referee_llm_det(q, draft, lo, hi)\n",
    "\n",
    "    if state == \"accept\":\n",
    "        answer, human_min, prov = draft, 0.0, \"generator\"\n",
    "\n",
    "    elif state == \"reject\":\n",
    "        answer, human_min, prov = judge_external(row, \"reject\")\n",
    "\n",
    "    else:  # state == \"defer\"\n",
    "        answer, human_min, prov = None, 0.0, \"deferred\"\n",
    "        # no judge call, no memory write\n",
    "\n",
    "    # only write memory when we actually have an answer\n",
    "    if answer is not None:\n",
    "        write_memory(hash(q), answer)\n",
    "\n",
    "    ledger_pass1.append(dict(\n",
    "        query_id=int(row.id),\n",
    "        draft=draft,\n",
    "        state=state,\n",
    "        answer=answer,\n",
    "        human_min=human_min,\n",
    "        latency_s=round(time.time()-t0,3),\n",
    "    ))\n",
    "\n",
    "dest_path = OUT_DIR / f\"ledger_pass1_{RUN_ID}.jsonl\"\n",
    "\n",
    "with dest_path.open(\"w\") as f:\n",
    "    for rec in ledger_pass1:\n",
    "        f.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "print(\"PASS-1 complete; ledger saved to:\", dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# ║ KPI REPORT · Pass 1                                              ║\n",
    "# ╠══════════════════════════════════════════════════════════════════╣\n",
    "# ║ • `compute_kpi()` loads the JSONL ledger we just wrote and       ║\n",
    "# ║   returns a dict of headline metrics (accept/reject/defer rates, ║\n",
    "# ║   average latency, human-minutes, monetised cost, …).            ║\n",
    "# ║ • `pretty_print_kpi()` renders that dict as a human-friendly      ║\n",
    "# ║   summary block in the notebook output.                          ║\n",
    "# ║                                                                  ║\n",
    "# ║   Input  : PASS1_OUT   → ./outputs/ledger_pass1_<RUN_ID>.jsonl   ║\n",
    "# ║   Output : nicely-formatted KPI table in the cell’s stdout.      ║\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "kpi1 = compute_kpi(PASS1_OUT)\n",
    "pretty_print_kpi(kpi1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ╔════════════════════════════════════════════════════════════════════╗\n",
    "# ║ PASS-2 · “Defer-fix” sweep                                         ║\n",
    "# ╠════════════════════════════════════════════════════════════════════╣\n",
    "# ║ Goal                                                              ║\n",
    "# ║ ────────────────────────────────────────────────────────────────── ║\n",
    "# ║ • Re-load the Pass-1 ledger.                                      ║\n",
    "# ║ • Any query that was *accepted* or *rejected* in Pass-1 is         ║\n",
    "# ║   copied through unchanged (state_p2 = original state).            ║\n",
    "# ║ • Any query that was *deferred* is now sent to the simulated       ║\n",
    "# ║   External Judge C:                                                ║\n",
    "# ║       – pull authoritative value from ground_truth CSV            ║\n",
    "# ║       – mark the new verdict as “accept” (always in-range)        ║\n",
    "# ║       – add 1.0 human_min   (full expert minute)                  ║\n",
    "# ║       – add 0.25 s latency  (lookup delay)                        ║\n",
    "# ║       – provenance tag  =  'fallback:defer_fix'                   ║\n",
    "# ║       – write answer to precedent store via `write_memory()`      ║\n",
    "# ║ • Serialise the resulting list to  ./outputs/ledger_pass2_<id>.   ║\n",
    "# ║ • Pass-2 therefore eliminates all defers and yields 100 %         ║\n",
    "# ║   coverage before we compute KPI_2 / plots.                       ║\n",
    "# ╚════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "ledger_pass1 = pd.read_json(PASS1_OUT, lines=True)\n",
    "gt      = pd.read_csv(GT_PATH).set_index(\"id\")\n",
    "\n",
    "for rec in ledger_pass1.to_dict(\"records\"):\n",
    "    if rec[\"state\"] != \"defer\":\n",
    "        rec[\"state_p2\"] = rec[\"state\"]     # keep old verdict as the pass-2 verdict\n",
    "        ledger_pass2.append(rec)                 # accept / reject unchanged\n",
    "        continue\n",
    "\n",
    "    # --- Judge C supplies authoritative value ---\n",
    "    val = gt.loc[rec[\"query_id\"], \"answer\"]\n",
    "\n",
    "    lo, hi = val*LOWER_TOL_FACTOR, val*UPPER_TOL_FACTOR\n",
    "    state2 = \"accept\" if lo <= val <= hi else \"reject\"   # should be accept\n",
    "\n",
    "    rec.update({\n",
    "        \"state_p2\": state2,\n",
    "        \"answer\": val,\n",
    "        \"human_min\": 1.0,                 # simulated deeper lookup\n",
    "        \"provenance\": \"fallback:defer_fix\",\n",
    "        \"extra_latency_s\": 0.25,\n",
    "    })\n",
    "    write_memory(hash(rec[\"draft\"]), val)\n",
    "    ledger_pass2.append(rec)\n",
    "\n",
    "# dump Pass 2 ledger\n",
    "dest_path = OUT_DIR / f\"ledger_pass2_{RUN_ID}.jsonl\"\n",
    "\n",
    "with dest_path.open(\"w\") as f:\n",
    "    for rec in ledger_pass2:\n",
    "        f.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "print(\"PASS-2 complete; ledger saved to:\", dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════╗\n",
    "# ║ KPI REPORT · Pass 2 (after defer-fix)                            ║\n",
    "# ╠══════════════════════════════════════════════════════════════════╣\n",
    "# ║ • `compute_kpi()` loads the Pass-2 ledger we just wrote and       ║\n",
    "# ║   recalculates all headline metrics.                             ║\n",
    "# ║ • `pretty_print_kpi()` prints the same nicely-formatted summary   ║\n",
    "# ║   so we can compare directly with the Pass-1 table above.        ║\n",
    "# ║                                                                  ║\n",
    "# ║   Input  : PASS2_OUT → ./outputs/ledger_pass2_<RUN_ID>.jsonl     ║\n",
    "# ║   Output : KPI table for Pass 2 in cell stdout.                  ║\n",
    "# ╚══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "kpi2 = compute_kpi(PASS2_OUT)\n",
    "pretty_print_kpi(kpi2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ╔═════════════════════════════════════════════════════════════════╗\n",
    "# ║ VISUAL SUMMARY · Pass-1  vs  Pass-2                            ║\n",
    "# ╠═════════════════════════════════════════════════════════════════╣\n",
    "# ║ • `plot_comparison()` draws two side-by-side figures:           ║\n",
    "# ║       1.  Bar chart of accept / reject / defer share            ║\n",
    "# ║           (colours stay consistent across passes).              ║\n",
    "# ║       2.  Bar chart of total \\$ cost for each pass.             ║\n",
    "# ║ • PNGs are saved to  OUT_DIR / {kpi_bar.png, cost_bar.png}      ║\n",
    "# ║   so they can be embedded in the README, plus rendered inline.  ║\n",
    "# ╚═════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "plot_comparison(kpi1, kpi2, out_dir=OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
